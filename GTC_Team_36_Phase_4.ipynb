{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 1650695,
          "sourceType": "datasetVersion",
          "datasetId": 976194
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Environment-agnostic dataset root resolver ---\n",
        "from pathlib import Path\n",
        "\n",
        "# If we're on Kaggle, this exists:\n",
        "kaggle_root = Path(\"/kaggle/input/kitti-dataset\")\n",
        "\n",
        "# If we're outside Kaggle but downloaded with kagglehub, use that:\n",
        "try:\n",
        "    hub_root = Path(klemenko_kitti_dataset_path)\n",
        "except NameError:\n",
        "    hub_root = None\n",
        "\n",
        "if kaggle_root.exists():\n",
        "    DATASET_ROOT = kaggle_root\n",
        "elif hub_root and hub_root.exists():\n",
        "    DATASET_ROOT = hub_root\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"KITTI data not found. Either run on Kaggle (where /kaggle/input/kitti-dataset exists) \"\n",
        "        \"or ensure kagglehub.download() finished and klemenko_kitti_dataset_path is valid.\"\n",
        "    )\n",
        "\n",
        "print(\"Using KITTI dataset root:\", DATASET_ROOT)"
      ],
      "metadata": {
        "id": "j6y0kSEE5Ah2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1"
      ],
      "metadata": {
        "id": "F1HDfVGMzNZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Packages"
      ],
      "metadata": {
        "id": "naS4bxzdzNZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install everything we actually use\n",
        "!pip install -q ultralytics tqdm opencv-python-headless matplotlib pyyaml scikit-learn\n",
        "\n",
        "# Make Ultralytics not initialize W&B (saves RAM / avoids login prompts)\n",
        "from ultralytics.utils import SETTINGS\n",
        "SETTINGS.update({'wandb': False})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:35.685394Z",
          "iopub.execute_input": "2025-09-23T20:40:35.686116Z",
          "iopub.status.idle": "2025-09-23T20:40:38.958059Z",
          "shell.execute_reply.started": "2025-09-23T20:40:35.686078Z",
          "shell.execute_reply": "2025-09-23T20:40:38.957023Z"
        },
        "id": "WT0HfoYfzNZf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import random"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T23:05:20.518307Z",
          "iopub.execute_input": "2025-09-23T23:05:20.518606Z",
          "iopub.status.idle": "2025-09-23T23:05:20.523045Z",
          "shell.execute_reply.started": "2025-09-23T23:05:20.518584Z",
          "shell.execute_reply": "2025-09-23T23:05:20.522304Z"
        },
        "id": "w8GFmhKNzNZg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Project Folder Structure"
      ],
      "metadata": {
        "id": "9SKuJF6_zNZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path('./kitti_phase1')\n",
        "EXTRACT_DIR = PROJECT_ROOT / 'kitti_extracted'   # kept for parity with original notebook\n",
        "YOLO_DIR = PROJECT_ROOT / 'kitti_yolo'\n",
        "\n",
        "for d in [EXTRACT_DIR, YOLO_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "(YOLO_IMAGES_TRAIN := YOLO_DIR / 'images' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "(YOLO_LABELS_TRAIN := YOLO_DIR / 'labels' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "(YOLO_IMAGES_VAL   := YOLO_DIR / 'images' / 'val').mkdir(parents=True, exist_ok=True)\n",
        "(YOLO_LABELS_VAL   := YOLO_DIR / 'labels' / 'val').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PROJECT_ROOT, EXTRACT_DIR, YOLO_DIR"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:39.807091Z",
          "iopub.execute_input": "2025-09-23T20:40:39.807459Z",
          "iopub.status.idle": "2025-09-23T20:40:39.815768Z",
          "shell.execute_reply.started": "2025-09-23T20:40:39.80744Z",
          "shell.execute_reply": "2025-09-23T20:40:39.81527Z"
        },
        "id": "H8mBwt15zNZh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select KITTI Paths from Kaggle Input"
      ],
      "metadata": {
        "id": "2G5ifiu2zNZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "KAGGLE_KITTI = DATASET_ROOT\n",
        "\n",
        "TRAIN_IMAGES_DIR = KAGGLE_KITTI / \"data_object_image_2\" / \"training\" / \"image_2\"\n",
        "TEST_IMAGES_DIR  = KAGGLE_KITTI / \"data_object_image_2\" / \"testing\"  / \"image_2\"\n",
        "LABELS_DIR       = KAGGLE_KITTI / \"data_object_label_2\" / \"training\" / \"label_2\"\n",
        "\n",
        "IMAGES_DIR = TRAIN_IMAGES_DIR  # we convert from the labeled TRAIN split\n",
        "\n",
        "print(\"Train images folder:\", TRAIN_IMAGES_DIR)\n",
        "print(\"Test  images folder:\", TEST_IMAGES_DIR)\n",
        "print(\"Labels folder      :\", LABELS_DIR)\n",
        "\n",
        "# Early path asserts to fail fast if anything's missing\n",
        "for p in [TRAIN_IMAGES_DIR, TEST_IMAGES_DIR, LABELS_DIR]:\n",
        "    assert p.exists(), f\"Missing folder: {p}\"\n",
        "\n",
        "print(\"Number of TRAIN images:\", len(list(TRAIN_IMAGES_DIR.glob('*.png'))))\n",
        "print(\"Number of TEST  images:\", len(list(TEST_IMAGES_DIR.glob('*.png'))))\n",
        "print(\"Number of TRAIN labels:\", len(list(LABELS_DIR.glob('*.txt'))))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:39.817615Z",
          "iopub.execute_input": "2025-09-23T20:40:39.817887Z",
          "iopub.status.idle": "2025-09-23T20:40:39.87624Z",
          "shell.execute_reply.started": "2025-09-23T20:40:39.81787Z",
          "shell.execute_reply": "2025-09-23T20:40:39.87568Z"
        },
        "id": "UpEy9f0MzNZi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Image and Label Directories, Preview a Sample Image, and Preview the Matching Label File"
      ],
      "metadata": {
        "id": "j0C1ZXX_zNZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, matplotlib.pyplot as plt\n",
        "\n",
        "sample_img_path = sorted(IMAGES_DIR.glob('*.png'))[0]\n",
        "img = cv2.cvtColor(cv2.imread(str(sample_img_path)), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(sample_img_path.name)\n",
        "plt.show()\n",
        "\n",
        "sample_lbl_path = LABELS_DIR / (sample_img_path.stem + '.txt')\n",
        "print(\"Label file:\", sample_lbl_path.name)\n",
        "print(\"\\n\".join(open(sample_lbl_path).read().splitlines()[:10]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:39.876852Z",
          "iopub.execute_input": "2025-09-23T20:40:39.877089Z",
          "iopub.status.idle": "2025-09-23T20:40:40.162613Z",
          "shell.execute_reply.started": "2025-09-23T20:40:39.877066Z",
          "shell.execute_reply": "2025-09-23T20:40:40.161917Z"
        },
        "id": "X5_EK9sgzNZi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for Missing or Empty Labels"
      ],
      "metadata": {
        "id": "kgvH7gsCzNZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "images = sorted(IMAGES_DIR.glob('*.png'))\n",
        "labels = sorted(LABELS_DIR.glob('*.txt'))\n",
        "img_set = {p.stem for p in images}\n",
        "lbl_set = {p.stem for p in labels}\n",
        "\n",
        "imgs_without_lbl = [p for p in images if p.stem not in lbl_set]\n",
        "lbl_without_imgs = [p for p in labels if p.stem not in img_set]\n",
        "empty_label_files = [p for p in labels if p.stat().st_size == 0]\n",
        "\n",
        "print(\"Images without label:\", len(imgs_without_lbl))\n",
        "print(\"Labels without image:\", len(lbl_without_imgs))\n",
        "print(\"Empty label files:\", len(empty_label_files))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:40.163366Z",
          "iopub.execute_input": "2025-09-23T20:40:40.163602Z",
          "iopub.status.idle": "2025-09-23T20:40:57.153449Z",
          "shell.execute_reply.started": "2025-09-23T20:40:40.163581Z",
          "shell.execute_reply": "2025-09-23T20:40:57.152719Z"
        },
        "id": "Ewn_OZaRzNZj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Missing/Empty Label Files"
      ],
      "metadata": {
        "id": "Q7s1IyGAzNZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels = {p.stem for p in labels if p.stat().st_size > 0}\n",
        "images = [p for p in images if p.stem in valid_labels]  # keep images with non-empty label\n",
        "print(\"Usable images after removing missing/empty labels:\", len(images))\n",
        "\n",
        "CLEAN_REPORT = {\n",
        "    \"imgs_without_lbl\": [p.name for p in imgs_without_lbl],\n",
        "    \"lbl_without_imgs\": [p.name for p in lbl_without_imgs],\n",
        "    \"empty_label_files\": [p.name for p in empty_label_files],\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:57.15436Z",
          "iopub.execute_input": "2025-09-23T20:40:57.154916Z",
          "iopub.status.idle": "2025-09-23T20:40:57.214715Z",
          "shell.execute_reply.started": "2025-09-23T20:40:57.154893Z",
          "shell.execute_reply": "2025-09-23T20:40:57.213993Z"
        },
        "id": "yfVu-tlgzNZj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Duplicate Images"
      ],
      "metadata": {
        "id": "Sh8jQMdXzNZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Robust duplicate detection on Kaggle FUSE (handles Errno 512) ---\n",
        "import hashlib, time, os\n",
        "\n",
        "def file_md5_resilient(path, chunk=1<<20, retries=3, pause=0.3):\n",
        "    \"\"\"MD5 with small retries to tolerate transient FUSE read errors.\"\"\"\n",
        "    for attempt in range(1, retries+1):\n",
        "        try:\n",
        "            h = hashlib.md5()\n",
        "            with open(path, \"rb\") as f:\n",
        "                while True:\n",
        "                    data = f.read(chunk)\n",
        "                    if not data:\n",
        "                        break\n",
        "                    h.update(data)\n",
        "            return h.hexdigest()\n",
        "        except OSError as e:\n",
        "            if attempt == retries:\n",
        "                raise\n",
        "            time.sleep(pause)\n",
        "    return None  # should not reach\n",
        "\n",
        "hash_seen = set()\n",
        "unique_images = []\n",
        "dupe_images = []\n",
        "unreadable_images = []\n",
        "\n",
        "for p in images:\n",
        "    try:\n",
        "        h = file_md5_resilient(p)\n",
        "        if h in hash_seen:\n",
        "            dupe_images.append(p)\n",
        "        else:\n",
        "            hash_seen.add(h)\n",
        "            unique_images.append(p)\n",
        "    except OSError as e:\n",
        "        # Skip files that the FUSE mount refuses to read; log for report\n",
        "        unreadable_images.append(p)\n",
        "\n",
        "# keep only readable, non-duplicate files\n",
        "images = unique_images\n",
        "\n",
        "print(\"Removed duplicate images:\", len(dupe_images))\n",
        "print(\"Skipped unreadable images (FUSE error):\", len(unreadable_images))\n",
        "\n",
        "CLEAN_REPORT[\"duplicate_images\"]  = [p.name for p in dupe_images]\n",
        "CLEAN_REPORT[\"unreadable_images\"] = [p.name for p in unreadable_images]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:40:57.215552Z",
          "iopub.execute_input": "2025-09-23T20:40:57.215941Z",
          "iopub.status.idle": "2025-09-23T20:41:24.550927Z",
          "shell.execute_reply.started": "2025-09-23T20:40:57.215916Z",
          "shell.execute_reply": "2025-09-23T20:41:24.550197Z"
        },
        "id": "bL-YbxWIzNZk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Bounding Boxes on a Sample Image"
      ],
      "metadata": {
        "id": "EZWQUqUHzNZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "\n",
        "def read_kitti_objects(lbl_path):\n",
        "    objs = []\n",
        "    for line in open(lbl_path).read().splitlines():\n",
        "        parts = line.split()\n",
        "        if len(parts) < 8:\n",
        "            continue\n",
        "        cls = parts[0]\n",
        "        try:\n",
        "            x1, y1, x2, y2 = map(float, parts[4:8])\n",
        "            objs.append({'cls': cls, 'bbox': [x1, y1, x2, y2]})\n",
        "        except:\n",
        "            continue\n",
        "    return objs\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "\n",
        "objs = read_kitti_objects(sample_lbl_path)\n",
        "for o in objs[:10]:\n",
        "    x1, y1, x2, y2 = o['bbox']\n",
        "    rect = patches.Rectangle((x1,y1), x2-x1, y2-y1, linewidth=2, edgecolor='yellow', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(x1, y1-3, o['cls'], fontsize=8, color='yellow', backgroundcolor='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:41:24.551716Z",
          "iopub.execute_input": "2025-09-23T20:41:24.551971Z",
          "iopub.status.idle": "2025-09-23T20:41:24.711305Z",
          "shell.execute_reply.started": "2025-09-23T20:41:24.551948Z",
          "shell.execute_reply": "2025-09-23T20:41:24.71069Z"
        },
        "id": "1bC-UqV8zNZk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Classes and Label Conversion Functions"
      ],
      "metadata": {
        "id": "wPjetpRlzNZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = ['Car', 'Pedestrian', 'Cyclist']\n",
        "CLASS_TO_ID = {c:i for i,c in enumerate(CLASSES)}\n",
        "\n",
        "def kitti_to_yolo_bbox(x1, y1, x2, y2, W, H):\n",
        "    x_center = ((x1 + x2) / 2.0) / W\n",
        "    y_center = ((y1 + y2) / 2.0) / H\n",
        "    w = (x2 - x1) / W\n",
        "    h = (y2 - y1) / H\n",
        "    return x_center, y_center, w, h"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:41:24.714474Z",
          "iopub.execute_input": "2025-09-23T20:41:24.714736Z",
          "iopub.status.idle": "2025-09-23T20:41:24.720189Z",
          "shell.execute_reply.started": "2025-09-23T20:41:24.714716Z",
          "shell.execute_reply": "2025-09-23T20:41:24.719373Z"
        },
        "id": "YsZgZh_8zNZk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert KITTI Labels to YOLO Format with Outlier Filtering"
      ],
      "metadata": {
        "id": "9ej7vRpqzNZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_file_to_yolo(img_path, lbl_path):\n",
        "    import cv2, math\n",
        "    H, W = cv2.imread(str(img_path)).shape[:2]\n",
        "    lines_out = []\n",
        "    min_area_frac = 1e-5      # drop boxes smaller than this fraction of image area\n",
        "    max_area_frac = 0.8       # drop boxes that cover almost whole image\n",
        "    max_aspect = 20.0         # drop boxes with extreme aspect ratio\n",
        "\n",
        "    for line in open(lbl_path).read().splitlines():\n",
        "        parts = line.split()\n",
        "        if len(parts) < 8:\n",
        "            continue\n",
        "        cls = parts[0]\n",
        "        if cls not in CLASS_TO_ID:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = map(float, parts[4:8])\n",
        "        # clamp to image bounds\n",
        "        x1, y1 = max(0.0, x1), max(0.0, y1)\n",
        "        x2, y2 = min(float(W-1), x2), min(float(H-1), y2)\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            continue\n",
        "\n",
        "        # outlier checks\n",
        "        bw, bh = (x2 - x1), (y2 - y1)\n",
        "        area_frac = (bw * bh) / float(W * H)\n",
        "        aspect = max(bw / max(bh,1e-6), bh / max(bw,1e-6))\n",
        "        if area_frac < min_area_frac or area_frac > max_area_frac or aspect > max_aspect:\n",
        "            continue\n",
        "\n",
        "        xc = ((x1 + x2) / 2.0) / W\n",
        "        yc = ((y1 + y2) / 2.0) / H\n",
        "        w  = bw / W\n",
        "        h  = bh / H\n",
        "        if w <= 0 or h <= 0:\n",
        "            continue\n",
        "\n",
        "        lines_out.append(f\"{CLASS_TO_ID[cls]} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\")\n",
        "    return lines_out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:41:24.721112Z",
          "iopub.execute_input": "2025-09-23T20:41:24.721406Z",
          "iopub.status.idle": "2025-09-23T20:41:24.736104Z",
          "shell.execute_reply.started": "2025-09-23T20:41:24.721388Z",
          "shell.execute_reply": "2025-09-23T20:41:24.735409Z"
        },
        "id": "MaHMlMIPzNZl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Dataset into Train (80%) and Validation (20%)"
      ],
      "metadata": {
        "id": "ogDPU0WEzNZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, shutil\n",
        "random.seed(42)\n",
        "\n",
        "usable_images = [p for p in images if (LABELS_DIR / (p.stem + '.txt')).exists()]\n",
        "random.shuffle(usable_images)\n",
        "\n",
        "split_idx = int(0.8 * len(usable_images))\n",
        "train_imgs = usable_images[:split_idx]\n",
        "val_imgs = usable_images[split_idx:]\n",
        "\n",
        "def process_split(img_paths, images_out_dir, labels_out_dir):\n",
        "    images_out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    labels_out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    kept, skipped = 0, 0\n",
        "    for ip in tqdm(img_paths):\n",
        "        lp = LABELS_DIR / (ip.stem + '.txt')\n",
        "        lines = convert_file_to_yolo(ip, lp)\n",
        "        if len(lines) == 0:\n",
        "            skipped += 1\n",
        "            continue\n",
        "        shutil.copy2(ip, images_out_dir / ip.name)\n",
        "        with open(labels_out_dir / (ip.stem + '.txt'), 'w') as f:\n",
        "            f.write('\\n'.join(lines) + '\\n')\n",
        "        kept += 1\n",
        "    return kept, skipped\n",
        "\n",
        "kept_tr, skip_tr = process_split(train_imgs, YOLO_IMAGES_TRAIN, YOLO_LABELS_TRAIN)\n",
        "kept_va, skip_va = process_split(val_imgs, YOLO_IMAGES_VAL, YOLO_LABELS_VAL)\n",
        "\n",
        "print({'train_kept': kept_tr, 'train_skipped': skip_tr, 'val_kept': kept_va, 'val_skipped': skip_va})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:41:24.736817Z",
          "iopub.execute_input": "2025-09-23T20:41:24.736996Z",
          "iopub.status.idle": "2025-09-23T20:43:31.227724Z",
          "shell.execute_reply.started": "2025-09-23T20:41:24.736982Z",
          "shell.execute_reply": "2025-09-23T20:43:31.226685Z"
        },
        "id": "VCYZfcv-zNZl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write YOLO Data Configuration (data.yaml)"
      ],
      "metadata": {
        "id": "7Xe8vfpYzNZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "data_yaml = {\n",
        "    'path': str(YOLO_DIR.resolve()),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'names': CLASSES,\n",
        "}\n",
        "with open(YOLO_DIR / 'data.yaml', 'w') as f:\n",
        "    yaml.safe_dump(data_yaml, f, sort_keys=False)\n",
        "print((YOLO_DIR / 'data.yaml').read_text())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:43:31.228743Z",
          "iopub.execute_input": "2025-09-23T20:43:31.229018Z",
          "iopub.status.idle": "2025-09-23T20:43:31.253313Z",
          "shell.execute_reply.started": "2025-09-23T20:43:31.228986Z",
          "shell.execute_reply": "2025-09-23T20:43:31.252477Z"
        },
        "id": "pKHLsEqVzNZl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Train/Val Images and Labels and Package Final YOLO Dataset as ZIP"
      ],
      "metadata": {
        "id": "b50xWp8VzNZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_tr_img = len(list((YOLO_IMAGES_TRAIN).glob('*.png')))\n",
        "n_tr_lbl = len(list((YOLO_LABELS_TRAIN).glob('*.txt')))\n",
        "n_va_img = len(list((YOLO_IMAGES_VAL).glob('*.png')))\n",
        "n_va_lbl = len(list((YOLO_LABELS_VAL).glob('*.txt')))\n",
        "\n",
        "print('Train images:', n_tr_img, '| Train labels:', n_tr_lbl)\n",
        "print('Val images  :', n_va_img, '| Val labels  :', n_va_lbl)\n",
        "\n",
        "import shutil\n",
        "zip_path = PROJECT_ROOT / 'kitti_yolo_prepared.zip'\n",
        "if zip_path.exists(): zip_path.unlink()\n",
        "shutil.make_archive(str(zip_path.with_suffix('')), 'zip', root_dir=YOLO_DIR)\n",
        "print(\"ZIP written to:\", zip_path.resolve())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:43:31.254227Z",
          "iopub.execute_input": "2025-09-23T20:43:31.254502Z",
          "iopub.status.idle": "2025-09-23T20:47:35.191139Z",
          "shell.execute_reply.started": "2025-09-23T20:43:31.254478Z",
          "shell.execute_reply": "2025-09-23T20:47:35.190322Z"
        },
        "id": "MAx3HQE3zNZm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Cleaning Report as JSON"
      ],
      "metadata": {
        "id": "yTEuke4jzNZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "CLEAN_REPORT.update({\n",
        "    \"train_kept\": kept_tr, \"train_skipped\": skip_tr,\n",
        "    \"val_kept\": kept_va,   \"val_skipped\": skip_va\n",
        "})\n",
        "with open(PROJECT_ROOT / \"cleaning_report.json\", \"w\") as f:\n",
        "    json.dump(CLEAN_REPORT, f, indent=2)\n",
        "print(\"Saved cleaning_report.json\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:47:35.191996Z",
          "iopub.execute_input": "2025-09-23T20:47:35.192822Z",
          "iopub.status.idle": "2025-09-23T20:47:35.198048Z",
          "shell.execute_reply.started": "2025-09-23T20:47:35.192793Z",
          "shell.execute_reply": "2025-09-23T20:47:35.197221Z"
        },
        "id": "sqZf35qrzNZm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2"
      ],
      "metadata": {
        "id": "KzPzYN9vzNZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load YOLO Dataset Metadata"
      ],
      "metadata": {
        "id": "0Jaa71qWzNZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "YOLO_DIR = (PROJECT_ROOT / \"kitti_yolo\").resolve()\n",
        "\n",
        "train_images = sorted((YOLO_DIR / \"images\" / \"train\").glob(\"*.png\"))\n",
        "train_labels = sorted((YOLO_DIR / \"labels\" / \"train\").glob(\"*.txt\"))\n",
        "val_images   = sorted((YOLO_DIR / \"images\" / \"val\").glob(\"*.png\"))\n",
        "val_labels   = sorted((YOLO_DIR / \"labels\" / \"val\").glob(\"*.txt\"))\n",
        "\n",
        "print(\"Train images:\", len(train_images), \"Train labels:\", len(train_labels))\n",
        "print(\"Val images  :\", len(val_images), \"Val labels  :\", len(val_labels))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:47:35.198876Z",
          "iopub.execute_input": "2025-09-23T20:47:35.199154Z",
          "iopub.status.idle": "2025-09-23T20:47:35.386057Z",
          "shell.execute_reply.started": "2025-09-23T20:47:35.199136Z",
          "shell.execute_reply": "2025-09-23T20:47:35.385364Z"
        },
        "id": "IDjpdJgVzNZn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse YOLO Label Files into DataFrame"
      ],
      "metadata": {
        "id": "2NXcu-LRzNZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "records = []\n",
        "for lbl in train_labels + val_labels:\n",
        "    split = \"train\" if \"train\" in str(lbl) else \"val\"\n",
        "    for line in open(lbl).read().splitlines():\n",
        "        cls, xc, yc, w, h = line.split()\n",
        "        records.append({\n",
        "            \"split\": split,\n",
        "            \"image\": lbl.stem + \".png\",\n",
        "            \"class_id\": int(cls),\n",
        "            \"x_center\": float(xc),\n",
        "            \"y_center\": float(yc),\n",
        "            \"width\": float(w),\n",
        "            \"height\": float(h),\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(records)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:47:35.386783Z",
          "iopub.execute_input": "2025-09-23T20:47:35.386994Z",
          "iopub.status.idle": "2025-09-23T20:47:35.728617Z",
          "shell.execute_reply.started": "2025-09-23T20:47:35.386979Z",
          "shell.execute_reply": "2025-09-23T20:47:35.727845Z"
        },
        "id": "B8t9OssOzNZn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:47:35.729428Z",
          "iopub.execute_input": "2025-09-23T20:47:35.729621Z",
          "iopub.status.idle": "2025-09-23T20:47:35.741286Z",
          "shell.execute_reply.started": "2025-09-23T20:47:35.729606Z",
          "shell.execute_reply": "2025-09-23T20:47:35.740467Z"
        },
        "id": "13fHt9_hzNZn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset size:\", len(df))\n",
        "print(\"Number of unique images:\", df[\"image\"].nunique())\n",
        "print(\"Classes:\", df[\"class_id\"].unique())\n",
        "print(\"Class counts:\\n\", df[\"class_id\"].value_counts())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:47:35.742144Z",
          "iopub.execute_input": "2025-09-23T20:47:35.742328Z",
          "iopub.status.idle": "2025-09-23T20:47:35.755283Z",
          "shell.execute_reply.started": "2025-09-23T20:47:35.742313Z",
          "shell.execute_reply": "2025-09-23T20:47:35.75469Z"
        },
        "id": "xprE2GWvzNZn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bounding Box Visualization"
      ],
      "metadata": {
        "id": "kvAcEcxCzNZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image_with_bboxes(image_name, df, images_dir):\n",
        "    sub = df[df[\"image\"] == image_name]\n",
        "    img_path = os.path.join(images_dir, image_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    for _, row in sub.iterrows():\n",
        "        x, y, bw, bh = row[\"x_center\"], row[\"y_center\"], row[\"width\"], row[\"height\"]\n",
        "        x1 = int((x - bw/2) * w)\n",
        "        y1 = int((y - bh/2) * h)\n",
        "        x2 = int((x + bw/2) * w)\n",
        "        y2 = int((y + bh/2) * h)\n",
        "\n",
        "        cls = row[\"class_id\"]\n",
        "        color = (0,255,0) if cls==0 else (255,0,0) if cls==1 else (0,0,255)\n",
        "        label = \"Car\" if cls==0 else \"Pedestrian\" if cls==1 else \"Cyclist\"\n",
        "\n",
        "        cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n",
        "        cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Bounding Boxes in {image_name}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:13.044256Z",
          "iopub.execute_input": "2025-09-23T21:54:13.044576Z",
          "iopub.status.idle": "2025-09-23T21:54:13.053344Z",
          "shell.execute_reply.started": "2025-09-23T21:54:13.044553Z",
          "shell.execute_reply": "2025-09-23T21:54:13.052505Z"
        },
        "id": "_nfwoAyJzNZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Diversity per Image"
      ],
      "metadata": {
        "id": "wJJBaAwezNZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diverse_imgs = df.groupby(\"image\")[\"class_id\"].nunique()\n",
        "diverse_imgs = diverse_imgs[diverse_imgs==3].index\n",
        "\n",
        "for img_name in diverse_imgs[:3]:\n",
        "    show_image_with_bboxes(img_name, df, str(IMAGES_DIR))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:04.182741Z",
          "iopub.execute_input": "2025-09-23T21:55:04.182966Z",
          "iopub.status.idle": "2025-09-23T21:55:04.911975Z",
          "shell.execute_reply.started": "2025-09-23T21:55:04.182949Z",
          "shell.execute_reply": "2025-09-23T21:55:04.911233Z"
        },
        "id": "2TZlZa5DzNZr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Distribution"
      ],
      "metadata": {
        "id": "X4C7JH5EzNZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fix dtype & palette for plotting ---\n",
        "import pandas as pd\n",
        "\n",
        "# ensure numeric class ids and keep only the three classes\n",
        "df[\"class_id\"] = pd.to_numeric(df[\"class_id\"], errors=\"coerce\")\n",
        "df = df[df[\"class_id\"].isin([0, 1, 2])].copy()\n",
        "df[\"class_id\"] = df[\"class_id\"].astype(int)\n",
        "\n",
        "CLS_ORDER = [0, 1, 2]\n",
        "PALETTE_INT = {0: \"#9370DB\", 1: \"#4682B4\", 2: \"#20B2AA\"}"
      ],
      "metadata": {
        "id": "lF0bsjUJEZKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(data=df, x=\"class_id\",\n",
        "              palette={'0': \"#4E79A7\", '1': \"#9370DB\", '2': \"#76B7B2\"})\n",
        "plt.xticks([0,1,2], ['Car','Pedestrian','Cyclist'])\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:04.059892Z",
          "iopub.execute_input": "2025-09-23T21:55:04.060119Z",
          "iopub.status.idle": "2025-09-23T21:55:04.181903Z",
          "shell.execute_reply.started": "2025-09-23T21:55:04.060101Z",
          "shell.execute_reply": "2025-09-23T21:55:04.181107Z"
        },
        "id": "9XPWx37zzNZs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"is_minority\"] = df[\"class_id\"].isin([1,2]).astype(int)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(data=df, x=\"is_minority\",\n",
        "              palette={'0': \"#4E79A7\", '1': \"#F28E2B\"})\n",
        "plt.xticks([0,1], [\"Majority (Car)\", \"Minority (Pedestrian/Cyclist)\"])\n",
        "plt.title(\"Minority Class Flag Distribution\")\n",
        "plt.xlabel(\"Class Group\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:03.925961Z",
          "iopub.execute_input": "2025-09-23T21:55:03.926199Z",
          "iopub.status.idle": "2025-09-23T21:55:04.058847Z",
          "shell.execute_reply.started": "2025-09-23T21:55:03.926181Z",
          "shell.execute_reply": "2025-09-23T21:55:04.058157Z"
        },
        "id": "Uf5xD2kozNZs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # Train vs Validation"
      ],
      "metadata": {
        "id": "iTR9jldozNZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(data=df,x=\"class_id\",hue=\"split\",palette=[\"#9370DB\", \"#4682B4\"])\n",
        "plt.xticks([0,1,2], ['Car','Pedestrian','Cyclist'])\n",
        "plt.title(\"Class Distribution (Train vs Val)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:03.772069Z",
          "iopub.execute_input": "2025-09-23T21:55:03.772312Z",
          "iopub.status.idle": "2025-09-23T21:55:03.92425Z",
          "shell.execute_reply.started": "2025-09-23T21:55:03.772289Z",
          "shell.execute_reply": "2025-09-23T21:55:03.923414Z"
        },
        "id": "jBR6nccrzNZs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bounding Box Derived Features"
      ],
      "metadata": {
        "id": "7HSWZxOEzNZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"bbox_area\"] = df[\"width\"] * df[\"height\"]\n",
        "df[\"aspect_ratio\"] = df[\"width\"] / df[\"height\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:07.598017Z",
          "iopub.execute_input": "2025-09-23T21:54:07.598341Z",
          "iopub.status.idle": "2025-09-23T21:54:07.606469Z",
          "shell.execute_reply.started": "2025-09-23T21:54:07.598318Z",
          "shell.execute_reply": "2025-09-23T21:54:07.60561Z"
        },
        "id": "yaH70BfqzNZt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:09.360025Z",
          "iopub.execute_input": "2025-09-23T21:54:09.360688Z",
          "iopub.status.idle": "2025-09-23T21:54:09.372367Z",
          "shell.execute_reply.started": "2025-09-23T21:54:09.360639Z",
          "shell.execute_reply": "2025-09-23T21:54:09.371697Z"
        },
        "id": "LLGJHaGUzNZt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(df[\"bbox_area\"],bins=50,kde=True,color=\"#9370DB\",edgecolor=\"black\")\n",
        "\n",
        "plt.title(\"Bounding Box Area Distribution\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.histplot(df[\"aspect_ratio\"],bins=50,kde=True,color=\"#008080\",edgecolor=\"black\")\n",
        "plt.title(\"Bounding Box Aspect Ratio Distribution\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:11.255031Z",
          "iopub.execute_input": "2025-09-23T21:54:11.255688Z",
          "iopub.status.idle": "2025-09-23T21:54:12.104096Z",
          "shell.execute_reply.started": "2025-09-23T21:54:11.255663Z",
          "shell.execute_reply": "2025-09-23T21:54:12.103162Z"
        },
        "id": "OiYvfRzWzNZt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "for img_name in random.sample(df['image'].unique().tolist(), 4):\n",
        "    show_image_with_bboxes(img_name, df, str(IMAGES_DIR))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:15.534002Z",
          "iopub.execute_input": "2025-09-23T21:54:15.534834Z",
          "iopub.status.idle": "2025-09-23T21:54:16.502109Z",
          "shell.execute_reply.started": "2025-09-23T21:54:15.534805Z",
          "shell.execute_reply": "2025-09-23T21:54:16.501404Z"
        },
        "collapsed": true,
        "id": "5GiteiMkzNZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "objs_per_img = df.groupby(\"image\")[\"class_id\"].count().reset_index(name=\"num_objects\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(objs_per_img[\"num_objects\"],bins=30,color=\"#9370DB\",edgecolor=\"black\")\n",
        "plt.title(\"Objects per Image Distribution\")\n",
        "plt.xlabel(\"Objects per image\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Avg objects per image:\", objs_per_img[\"num_objects\"].mean())\n",
        "print(\"Max objects in an image:\", objs_per_img[\"num_objects\"].max())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:19.234061Z",
          "iopub.execute_input": "2025-09-23T21:54:19.23436Z",
          "iopub.status.idle": "2025-09-23T21:54:19.437771Z",
          "shell.execute_reply.started": "2025-09-23T21:54:19.234337Z",
          "shell.execute_reply": "2025-09-23T21:54:19.436971Z"
        },
        "id": "a38120q8zNZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bounding Box Area per Class"
      ],
      "metadata": {
        "id": "qXXFxlnkzNZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "PALETTE_STR = {'0': \"#9370DB\", '1': \"#4682B4\", '2': \"#20B2AA\"}\n",
        "sns.boxplot(data=df, x=\"class_id\", y=\"bbox_area\", palette=PALETTE_STR)\n",
        "\n",
        "plt.xticks([0,1,2], ['Car','Pedestrian','Cyclist'])\n",
        "plt.yscale(\"log\")\n",
        "plt.title(\"Bounding Box Area Distribution per Class\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:21.883033Z",
          "iopub.execute_input": "2025-09-23T21:54:21.883392Z",
          "iopub.status.idle": "2025-09-23T21:54:22.23904Z",
          "shell.execute_reply.started": "2025-09-23T21:54:21.883365Z",
          "shell.execute_reply": "2025-09-23T21:54:22.23814Z"
        },
        "id": "hM2PhBhSzNZu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Center Heatmaps"
      ],
      "metadata": {
        "id": "UQTvoNyXzNZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "for i, cls in enumerate(['Car','Pedestrian','Cyclist']):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    subset = df[df[\"class_id\"]==i]\n",
        "    sns.kdeplot(x=subset[\"x_center\"], y=subset[\"y_center\"], cmap=\"mako\", fill=True, thresh=0.05)\n",
        "    plt.title(f\"{cls} Center Density\")\n",
        "    plt.xlabel(\"X Center\")\n",
        "    plt.ylabel(\"Y Center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:24.584222Z",
          "iopub.execute_input": "2025-09-23T21:54:24.584834Z",
          "iopub.status.idle": "2025-09-23T21:54:42.554089Z",
          "shell.execute_reply.started": "2025-09-23T21:54:24.584807Z",
          "shell.execute_reply": "2025-09-23T21:54:42.553279Z"
        },
        "id": "Z0kcgOORzNZv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Object Center Heatmap"
      ],
      "metadata": {
        "id": "-Oea_2_MzNZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "sns.kdeplot(\n",
        "    data=df, x=\"x_center\", y=\"y_center\",\n",
        "    hue=\"class_id\", fill=True, common_norm=False, alpha=0.4\n",
        ")\n",
        "plt.title(\"Object Center Heatmap per Class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:54:42.555491Z",
          "iopub.execute_input": "2025-09-23T21:54:42.555793Z",
          "iopub.status.idle": "2025-09-23T21:55:00.225005Z",
          "shell.execute_reply.started": "2025-09-23T21:54:42.555774Z",
          "shell.execute_reply": "2025-09-23T21:55:00.224263Z"
        },
        "id": "qJrVR6uNzNZv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Object Centers on Random Images"
      ],
      "metadata": {
        "id": "u_18AZBszNZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_object_centers(image_name, df, images_dir):\n",
        "    sub = df[df[\"image\"] == image_name]\n",
        "    img_path = os.path.join(images_dir, image_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    plt.imshow(img)\n",
        "    for _, row in sub.iterrows():\n",
        "        cx = int(row[\"x_center\"] * w)\n",
        "        cy = int(row[\"y_center\"] * h)\n",
        "        cls = row[\"class_id\"]\n",
        "\n",
        "        color = \"lime\" if cls==0 else \"orange\" if cls==1 else \"red\"\n",
        "        label = \"Car\" if cls==0 else \"Pedestrian\" if cls==1 else \"Cyclist\"\n",
        "\n",
        "        plt.scatter(cx, cy, c=color, s=50, edgecolors=\"black\")\n",
        "\n",
        "    plt.title(f\"Object Centers in {image_name}\")\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:00.225991Z",
          "iopub.execute_input": "2025-09-23T21:55:00.226332Z",
          "iopub.status.idle": "2025-09-23T21:55:00.233097Z",
          "shell.execute_reply.started": "2025-09-23T21:55:00.226305Z",
          "shell.execute_reply": "2025-09-23T21:55:00.232434Z"
        },
        "id": "Ss8fbtayzNZw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "random_imgs = df[\"image\"].drop_duplicates().sample(6, random_state=42).tolist()\n",
        "\n",
        "plt.figure(figsize=(12, 30))\n",
        "for i, img_name in enumerate(random_imgs, 1):\n",
        "    plt.subplot(6, 1, i)\n",
        "    show_object_centers(img_name, df, str(IMAGES_DIR))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:00.234957Z",
          "iopub.execute_input": "2025-09-23T21:55:00.235187Z",
          "iopub.status.idle": "2025-09-23T21:55:03.114704Z",
          "shell.execute_reply.started": "2025-09-23T21:55:00.235162Z",
          "shell.execute_reply": "2025-09-23T21:55:03.113512Z"
        },
        "id": "lVNstPd3zNZw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crowded Images & Rare Classes"
      ],
      "metadata": {
        "id": "nrhKAKCqzNZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_diversity = df.groupby(\"image\")[\"class_id\"].nunique().reset_index()\n",
        "class_diversity.rename(columns={\"class_id\": \"num_classes\"}, inplace=True)\n",
        "top_imgs = objs_per_img.sort_values(\"num_objects\", ascending=False).head(5)\n",
        "print(\"\\nTop crowded images:\\n\", top_imgs)\n",
        "\n",
        "rare_class_imgs = class_diversity[class_diversity[\"num_classes\"] == 1]\n",
        "print(\"\\nImages with only one class:\", len(rare_class_imgs))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:03.116026Z",
          "iopub.execute_input": "2025-09-23T21:55:03.116296Z",
          "iopub.status.idle": "2025-09-23T21:55:03.13826Z",
          "shell.execute_reply.started": "2025-09-23T21:55:03.116274Z",
          "shell.execute_reply": "2025-09-23T21:55:03.137617Z"
        },
        "id": "-fAQxOymzNZw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image_with_stats(image_name, df, images_dir):\n",
        "    sub = df[df[\"image\"] == image_name]\n",
        "    img_path = os.path.join(images_dir, image_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    h, w, _ = img.shape\n",
        "    for _, row in sub.iterrows():\n",
        "        x, y, bw, bh = row[\"x_center\"], row[\"y_center\"], row[\"width\"], row[\"height\"]\n",
        "        x1 = int((x - bw/2) * w)\n",
        "        y1 = int((y - bh/2) * h)\n",
        "        x2 = int((x + bw/2) * w)\n",
        "        y2 = int((y + bh/2) * h)\n",
        "\n",
        "        cls = row[\"class_id\"]\n",
        "        color = (0,255,0) if cls==0 else (255,0,0) if cls==1 else (0,0,255)\n",
        "        label = \"Car\" if cls==0 else \"Pedestrian\" if cls==1 else \"Cyclist\"\n",
        "\n",
        "        cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n",
        "        cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    counts = sub[\"class_id\"].value_counts().to_dict()\n",
        "    num_cars = counts.get(0, 0)\n",
        "    num_pedestrians = counts.get(1, 0)\n",
        "    num_cyclists = counts.get(2, 0)\n",
        "    total_objects = len(sub)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Image: {image_name} | Total: {total_objects} | Cars: {num_cars} | Pedestrians: {num_pedestrians} | Cyclists: {num_cyclists}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:03.139258Z",
          "iopub.execute_input": "2025-09-23T21:55:03.139485Z",
          "iopub.status.idle": "2025-09-23T21:55:03.147258Z",
          "shell.execute_reply.started": "2025-09-23T21:55:03.139468Z",
          "shell.execute_reply": "2025-09-23T21:55:03.146439Z"
        },
        "id": "LnSTcGG_zNZw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "top_imgs = objs_per_img.sort_values(\"num_objects\", ascending=False).head(3)\n",
        "for img_name in top_imgs[\"image\"]:\n",
        "    show_image_with_stats(img_name, df, str(IMAGES_DIR))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:03.148323Z",
          "iopub.execute_input": "2025-09-23T21:55:03.148927Z",
          "iopub.status.idle": "2025-09-23T21:55:03.749816Z",
          "shell.execute_reply.started": "2025-09-23T21:55:03.148899Z",
          "shell.execute_reply": "2025-09-23T21:55:03.749061Z"
        },
        "id": "by_-l9q3zNZx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "axhnhJi_zNZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total images:\", df[\"image\"].nunique())\n",
        "print(\"Total objects:\", len(df))\n",
        "\n",
        "print(\"\\nObjects per class:\\n\", df[\"class_id\"].value_counts())\n",
        "print(\"\\nAvg objects per image:\", objs_per_img[\"num_objects\"].mean())\n",
        "print(\"Max objects in an image:\", objs_per_img[\"num_objects\"].max())\n",
        "\n",
        "print(\"\\nClass diversity per image:\\n\", class_diversity[\"num_classes\"].value_counts().sort_index())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:55:03.75071Z",
          "iopub.execute_input": "2025-09-23T21:55:03.751196Z",
          "iopub.status.idle": "2025-09-23T21:55:03.771329Z",
          "shell.execute_reply.started": "2025-09-23T21:55:03.751158Z",
          "shell.execute_reply": "2025-09-23T21:55:03.770702Z"
        },
        "id": "lRF7wN0hzNZx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Classes to Make It Balanced"
      ],
      "metadata": {
        "id": "2JI-BGfIzNZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "df_clean = df.dropna(subset=[\"class_id\"]).copy()\n",
        "\n",
        "df_filtered = df_clean[df_clean[\"class_id\"].isin([0, 1, 2])]\n",
        "\n",
        "car_df = df_filtered[df_filtered[\"class_id\"] == 0]\n",
        "ped_df = df_filtered[df_filtered[\"class_id\"] == 1]\n",
        "cyc_df = df_filtered[df_filtered[\"class_id\"] == 2]\n",
        "\n",
        "print(\"Before balancing:\")\n",
        "print(df_filtered[\"class_id\"].value_counts())\n",
        "\n",
        "target_size = len(car_df)\n",
        "\n",
        "ped_upsampled = resample(\n",
        "    ped_df, replace=True,\n",
        "    n_samples=target_size, random_state=42\n",
        ")\n",
        "cyc_upsampled = resample(\n",
        "    cyc_df, replace=True,\n",
        "    n_samples=target_size, random_state=42\n",
        ")\n",
        "\n",
        "df_balanced = pd.concat([car_df, ped_upsampled, cyc_upsampled]).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nAfter balancing:\")\n",
        "print(df_balanced[\"class_id\"].value_counts())\n",
        "print(\"Balanced dataset size:\", len(df_balanced))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:08:13.632207Z",
          "iopub.execute_input": "2025-09-23T21:08:13.632937Z",
          "iopub.status.idle": "2025-09-23T21:08:13.660221Z",
          "shell.execute_reply.started": "2025-09-23T21:08:13.632911Z",
          "shell.execute_reply": "2025-09-23T21:08:13.659589Z"
        },
        "id": "Tl8AhXoKzNZy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(df_balanced, test_size=0.2, stratify=df_balanced[\"class_id\"], random_state=42)\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n",
        "print(\"Train class distribution:\\n\", train_df[\"class_id\"].value_counts())\n",
        "print(\"Val class distribution:\\n\", val_df[\"class_id\"].value_counts())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T20:50:35.575141Z",
          "iopub.execute_input": "2025-09-23T20:50:35.575791Z",
          "iopub.status.idle": "2025-09-23T20:50:35.761151Z",
          "shell.execute_reply.started": "2025-09-23T20:50:35.575768Z",
          "shell.execute_reply": "2025-09-23T20:50:35.760414Z"
        },
        "id": "kEf93Dg1zNZy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "import random\n",
        "\n",
        "def prepare_and_train_yolov8(df_balanced,\n",
        "                             orig_images_dir: Path,\n",
        "                             balanced_root_dir: Path,\n",
        "                             train_val_split: float = 0.2,\n",
        "                             sample_fraction: float = 1.0,\n",
        "                             epochs: int = 50,\n",
        "                             batch_size: int = 16,\n",
        "                             img_size: int = 640,\n",
        "                             device: int = 0):\n",
        "\n",
        "    img_train_dir = balanced_root_dir / \"images\" / \"train\"\n",
        "    lbl_train_dir = balanced_root_dir / \"labels\" / \"train\"\n",
        "    img_val_dir = balanced_root_dir / \"images\" / \"val\"\n",
        "    lbl_val_dir = balanced_root_dir / \"labels\" / \"val\"\n",
        "    for folder in [img_train_dir, lbl_train_dir, img_val_dir, lbl_val_dir]:\n",
        "        folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    unique_images = df_balanced[\"image\"].unique()\n",
        "    train_imgs, val_imgs = train_test_split(unique_images, test_size=train_val_split, random_state=42, shuffle=True)\n",
        "\n",
        "    random.seed(42)\n",
        "    train_imgs = random.sample(train_imgs.tolist(), int(len(train_imgs) * sample_fraction))\n",
        "    val_imgs = random.sample(val_imgs.tolist(), int(len(val_imgs) * sample_fraction))\n",
        "\n",
        "    grouped = df_balanced.groupby(\"image\")\n",
        "\n",
        "    def yolo_format(row):\n",
        "        return f\"{row['class_id']} {row['x_center']:.6f} {row['y_center']:.6f} {row['width']:.6f} {row['height']:.6f}\"\n",
        "\n",
        "    def copy_and_write(images, img_dir, lbl_dir):\n",
        "        for img_name in images:\n",
        "            shutil.copy2(orig_images_dir / img_name, img_dir / img_name)\n",
        "            labels = []\n",
        "            if img_name in grouped.groups:\n",
        "                labels = [yolo_format(row) for _, row in grouped.get_group(img_name).iterrows()]\n",
        "            with open(lbl_dir / (Path(img_name).stem + \".txt\"), \"w\") as f:\n",
        "                f.writelines(line + \"\\n\" for line in labels)\n",
        "\n",
        "    copy_and_write(train_imgs, img_train_dir, lbl_train_dir)\n",
        "    copy_and_write(val_imgs, img_val_dir, lbl_val_dir)\n",
        "\n",
        "    print(f\"Prepared {len(train_imgs)} train and {len(val_imgs)} val images with labels.\")\n",
        "    data_yaml = {\n",
        "        'path': str(balanced_root_dir.resolve()),\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'names': ['Car', 'Pedestrian', 'Cyclist']\n",
        "    }\n",
        "    with open(balanced_root_dir / \"data.yaml\", 'w') as f:\n",
        "        yaml.safe_dump(data_yaml, f, sort_keys=False)\n",
        "    print(f\"Saved data.yaml at {balanced_root_dir / 'data.yaml'}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:18:34.099702Z",
          "iopub.execute_input": "2025-09-23T21:18:34.100474Z",
          "iopub.status.idle": "2025-09-23T21:18:34.110336Z",
          "shell.execute_reply.started": "2025-09-23T21:18:34.100447Z",
          "shell.execute_reply": "2025-09-23T21:18:34.109352Z"
        },
        "id": "2swc9ebXzNZz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the balanced dataset that training will point to\n",
        "balanced_root_dir = Path(\"./kitti_balanced_yolo\")\n",
        "prepare_and_train_yolov8(\n",
        "    df_balanced=df_balanced,\n",
        "    orig_images_dir=IMAGES_DIR,\n",
        "    balanced_root_dir=balanced_root_dir,\n",
        "    train_val_split=0.2,\n",
        "    sample_fraction=1.0\n",
        ")\n",
        "assert (balanced_root_dir / \"data.yaml\").exists(), \"Expected balanced_root_dir/data.yaml to exist.\""
      ],
      "metadata": {
        "id": "WpHvJcRy5jnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training with duplicates removed"
      ],
      "metadata": {
        "id": "p047J8mazNZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Training (safe version) ----\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Choose transfer learning (recommended) or from-scratch (commented)\n",
        "model = YOLO('yolov8n.pt')     # or 'yolov8s.pt' if you have more compute\n",
        "# model = YOLO('yolov8n.yaml') # from scratch\n",
        "\n",
        "# Pick device safely (works on CPU/GPU)\n",
        "device = 0 if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Point to the dataset you want:\n",
        "# A) Balanced dataset (requires the call in Step 6)\n",
        "data_yaml_path = balanced_root_dir / \"data.yaml\"\n",
        "# B) Or original dataset you built earlier:\n",
        "# data_yaml_path = YOLO_DIR / \"data.yaml\"\n",
        "\n",
        "assert data_yaml_path.exists(), f\"data.yaml not found at {data_yaml_path}\"\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 8\n",
        "img_size = 640\n",
        "\n",
        "results = model.train(\n",
        "    data=str(data_yaml_path),\n",
        "    epochs=epochs,\n",
        "    batch=batch_size,\n",
        "    imgsz=img_size,\n",
        "    device=device,\n",
        "    workers=2,\n",
        "    flipud=0.5,\n",
        "    fliplr=0.5,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    project=\"runs/train\",\n",
        "    name=\"kitti_yolov8\",\n",
        "    exist_ok=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:22:21.941589Z",
          "iopub.execute_input": "2025-09-23T21:22:21.942241Z",
          "iopub.status.idle": "2025-09-23T21:22:21.946635Z",
          "shell.execute_reply.started": "2025-09-23T21:22:21.942215Z",
          "shell.execute_reply": "2025-09-23T21:22:21.94557Z"
        },
        "id": "pNjm3qNczNZz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Locate the freshly trained best.pt robustly ---\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "candidates = []\n",
        "try:\n",
        "    candidates.append(Path(results.save_dir) / \"weights\" / \"best.pt\")  # from Ultralytics Results\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Your named run (fallback)\n",
        "candidates.append(Path(\"runs/train/kitti_yolov8/weights/best.pt\"))\n",
        "\n",
        "# Newest best.pt anywhere\n",
        "cand_glob = sorted(Path(\"runs\").rglob(\"weights/best.pt\"),\n",
        "                   key=lambda p: p.stat().st_mtime if p.exists() else 0,\n",
        "                   reverse=True)\n",
        "candidates.extend(cand_glob)\n",
        "\n",
        "BEST_PT = next((p for p in candidates if p and p.exists()), None)\n",
        "assert BEST_PT is not None and BEST_PT.exists(), \"best.pt not found.\"\n",
        "\n",
        "def sha256(p: Path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(1<<20), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "print(\"best.pt:\", BEST_PT)\n",
        "print(\"size(MB):\", round(BEST_PT.stat().st_size/1e6, 2))\n",
        "print(\"sha256:\", sha256(BEST_PT))"
      ],
      "metadata": {
        "id": "gXuF4Hsj69gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "Xs1_jGguzNZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = model.val()\n",
        "print(eval_results)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T22:18:52.256976Z",
          "iopub.execute_input": "2025-09-23T22:18:52.257315Z",
          "iopub.status.idle": "2025-09-23T22:18:59.759759Z",
          "shell.execute_reply.started": "2025-09-23T22:18:52.257283Z",
          "shell.execute_reply": "2025-09-23T22:18:59.758918Z"
        },
        "collapsed": true,
        "id": "cISM_nK2zNZ0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# View predictions inline (no files saved)\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import gc, torch\n",
        "\n",
        "model = YOLO(str(BEST_PT))\n",
        "\n",
        "IMG_SIZE = 640\n",
        "CONF = 0.5\n",
        "IOU = 0.45\n",
        "MAX_SHOW = 30      # change to see more; large values can slow the notebook\n",
        "\n",
        "pred_gen = model.predict(\n",
        "    source=str(TEST_IMAGES_DIR),\n",
        "    imgsz=IMG_SIZE,\n",
        "    conf=CONF,\n",
        "    iou=IOU,\n",
        "    device=device,       # defined earlier (0 or 'cpu')\n",
        "    stream=True,         # generator = low memory\n",
        "    save=False,          # <-- don't save images\n",
        "    save_txt=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "shown = 0\n",
        "for r in pred_gen:\n",
        "    # r.plot() returns an annotated image (BGR)\n",
        "    im_annot = r.plot()\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(im_annot[..., ::-1])  # BGR -> RGB for matplotlib\n",
        "    plt.title(Path(r.path).name)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    shown += 1\n",
        "    plt.close()\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    if shown >= MAX_SHOW:\n",
        "        break"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T21:48:28.882586Z",
          "iopub.execute_input": "2025-09-23T21:48:28.883451Z",
          "iopub.status.idle": "2025-09-23T21:48:28.958771Z",
          "shell.execute_reply.started": "2025-09-23T21:48:28.883422Z",
          "shell.execute_reply": "2025-09-23T21:48:28.957936Z"
        },
        "id": "SJin8RROzNZ0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count objects in the predicted images Predicted"
      ],
      "metadata": {
        "id": "9hBav9oRzNaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Pick a real image folder that exists (no hard-coded Kaggle paths)\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "\n",
        "candidates = [\n",
        "    TEST_IMAGES_DIR,                                  # preferred: KITTI test images\n",
        "    YOLO_DIR / \"images\" / \"val\",                      # fallback: your YOLO val split\n",
        "    YOLO_DIR / \"images\" / \"train\",                    # fallback: your YOLO train split\n",
        "]\n",
        "if 'balanced_root_dir' in globals():\n",
        "    candidates += [balanced_root_dir / \"images\" / \"val\", balanced_root_dir / \"images\" / \"train\"]\n",
        "\n",
        "# keep only directories that exist and have at least one PNG\n",
        "def has_png(p: Path) -> bool:\n",
        "    return p and p.exists() and any(p.glob(\"*.png\"))\n",
        "\n",
        "candidates = [p for p in candidates if has_png(p)]\n",
        "assert candidates, \"No image directory with PNGs found in TEST/VAL/TRAIN candidates.\"\n",
        "\n",
        "SOURCE_DIR = candidates[0]\n",
        "print(\"Using images from:\", SOURCE_DIR)\n",
        "\n",
        "#  Show a few for sanity\n",
        "first_five = list(itertools.islice(SOURCE_DIR.glob(\"*.png\"), 5))\n",
        "print(\"Example files:\", [p.name for p in first_five])\n",
        "\n",
        "#  Predict & DISPLAY inline (nothing saved)\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, gc\n",
        "\n",
        "model = YOLO(str(BEST_PT))\n",
        "device = 0 if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "pred_gen = model.predict(\n",
        "    source=str(SOURCE_DIR),\n",
        "    imgsz=640, conf=0.5, iou=0.45,\n",
        "    device=device,\n",
        "    stream=True,      # low memory\n",
        "    save=False,       # do NOT save images\n",
        "    save_txt=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "MAX_SHOW = 30  # change if you want to view more/less\n",
        "for i, r in enumerate(pred_gen, start=1):\n",
        "    im_annot = r.plot()                # annotated BGR image\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(im_annot[..., ::-1])    # BGR -> RGB\n",
        "    plt.title(Path(r.path).name)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    if i >= MAX_SHOW:\n",
        "        break\n",
        "    plt.close(); gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T22:24:50.360585Z",
          "iopub.execute_input": "2025-09-23T22:24:50.360902Z",
          "iopub.status.idle": "2025-09-23T22:24:50.581218Z",
          "shell.execute_reply.started": "2025-09-23T22:24:50.36088Z",
          "shell.execute_reply": "2025-09-23T22:24:50.580626Z"
        },
        "id": "UspCjpPCzNaC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize first 5 prediction images with counts"
      ],
      "metadata": {
        "id": "6NNBJ7nxzNaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Predict on an existing directory, SHOW images inline, and PRINT per-image + total counts\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np, gc, torch\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Pick a source dir that actually exists\n",
        "candidates = [\n",
        "    TEST_IMAGES_DIR,\n",
        "    YOLO_DIR / \"images\" / \"val\",\n",
        "    YOLO_DIR / \"images\" / \"train\",\n",
        "]\n",
        "candidates = [p for p in candidates if p and p.exists() and any(p.glob(\"*.png\"))]\n",
        "assert candidates, \"No image directory with PNGs found in TEST/VAL/TRAIN.\"\n",
        "SOURCE_DIR = candidates[0]\n",
        "print(\"Using images from:\", SOURCE_DIR)\n",
        "\n",
        "# Load best weights\n",
        "model = YOLO(str(BEST_PT))\n",
        "device = 0 if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Class names (robust to dict/list forms)\n",
        "model_names = getattr(model, \"names\", None)\n",
        "if isinstance(model_names, dict):\n",
        "    class_names = [model_names[i] for i in sorted(model_names)]\n",
        "elif isinstance(model_names, (list, tuple)):\n",
        "    class_names = list(model_names)\n",
        "else:\n",
        "    class_names = [\"Car\", \"Pedestrian\", \"Cyclist\"]  # fallback\n",
        "\n",
        "# Stream predictions (low memory), don't save files\n",
        "pred_gen = model.predict(\n",
        "    source=str(SOURCE_DIR),\n",
        "    imgsz=640,\n",
        "    conf=0.5,\n",
        "    iou=0.45,\n",
        "    device=device,\n",
        "    batch=1,\n",
        "    stream=True,\n",
        "    save=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "total_counts = defaultdict(int)\n",
        "MAX_SHOW = 10  # show up to N images\n",
        "\n",
        "for i, r in enumerate(pred_gen, start=1):\n",
        "    # --- counts for this image ---\n",
        "    if hasattr(r, \"boxes\") and len(r.boxes):\n",
        "        cls_ids = r.boxes.cls.int().cpu().numpy()\n",
        "    else:\n",
        "        cls_ids = np.array([], dtype=int)\n",
        "\n",
        "    image_counts = defaultdict(int)\n",
        "    for cid in cls_ids:\n",
        "        name = class_names[int(cid)] if int(cid) < len(class_names) else str(int(cid))\n",
        "        image_counts[name] += 1\n",
        "        total_counts[name] += 1\n",
        "\n",
        "    print(f\"\\nImage {i}: {Path(r.path).name}\")\n",
        "    print(\"  Counts:\", dict(image_counts))\n",
        "\n",
        "    # --- show annotated image inline ---\n",
        "    im_annot = r.plot()                  # BGR\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(im_annot[..., ::-1])      # BGR -> RGB\n",
        "    plt.title(f\"{Path(r.path).name}  |  \" +\n",
        "              \"  \".join([f\"{k}:{v}\" for k,v in image_counts.items()]) if image_counts else \"No detections\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # housekeeping\n",
        "    del im_annot\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if i >= MAX_SHOW:\n",
        "        break\n",
        "\n",
        "# --- Totals across shown images ---\n",
        "print(\"\\nTotal predicted object counts (across shown images):\")\n",
        "for name in class_names:\n",
        "    print(f\"{name}: {total_counts[name]}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T22:38:36.63452Z",
          "iopub.execute_input": "2025-09-23T22:38:36.635334Z",
          "iopub.status.idle": "2025-09-23T22:38:38.357483Z",
          "shell.execute_reply.started": "2025-09-23T22:38:36.635298Z",
          "shell.execute_reply": "2025-09-23T22:38:38.356601Z"
        },
        "id": "qWM1aroXzNaC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confidence Heatmap Randomly sample 5 images"
      ],
      "metadata": {
        "id": "UFNQkwDdzNaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(str(BEST_PT))\n",
        "test_images_dir = TEST_IMAGES_DIR\n",
        "image_paths = list(test_images_dir.glob(\"*.png\"))\n",
        "sample_paths = random.sample(image_paths, 5)\n",
        "\n",
        "class_names = [\"Car\", \"Pedestrian\", \"Cyclist\"]\n",
        "\n",
        "for img_path in sample_paths:\n",
        "    img = cv2.imread(str(img_path))\n",
        "    if img is None:\n",
        "        print(f\"Could not read image: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
        "\n",
        "    results = model.predict(source=str(img_path), conf=0.5, save=False, stream=False)\n",
        "\n",
        "    r = results[0]\n",
        "    if hasattr(r, \"boxes\") and r.boxes is not None and len(r.boxes) > 0:\n",
        "        boxes = r.boxes.xyxy.cpu().numpy()\n",
        "        confs = r.boxes.conf.cpu().numpy()\n",
        "\n",
        "        for box, conf in zip(boxes, confs):\n",
        "            x1, y1, x2, y2 = box.astype(int)\n",
        "            # Clip coordinates\n",
        "            x1 = max(0, min(x1, img.shape[1] - 1))\n",
        "            x2 = max(0, min(x2, img.shape[1] - 1))\n",
        "            y1 = max(0, min(y1, img.shape[0] - 1))\n",
        "            y2 = max(0, min(y2, img.shape[0] - 1))\n",
        "            if x2 <= x1 or y2 <= y1:\n",
        "                continue\n",
        "            heatmap[y1:y2, x1:x2] = np.maximum(heatmap[y1:y2, x1:x2], conf)\n",
        "\n",
        "    heatmap_norm = heatmap / (heatmap.max() + 1e-6)\n",
        "    heatmap_smooth = gaussian_filter(heatmap_norm, sigma=5)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(img_rgb)\n",
        "    hmap = plt.imshow(heatmap_smooth, cmap='plasma', alpha=0.4, vmin=0, vmax=1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Confidence Heatmap: {img_path.name}\")\n",
        "    plt.colorbar(hmap, fraction=0.046, pad=0.04, label='Confidence')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T23:02:55.118434Z",
          "iopub.execute_input": "2025-09-23T23:02:55.118773Z",
          "iopub.status.idle": "2025-09-23T23:02:57.511804Z",
          "shell.execute_reply.started": "2025-09-23T23:02:55.118749Z",
          "shell.execute_reply": "2025-09-23T23:02:57.511113Z"
        },
        "id": "LCpHe8eSzNaC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    !pip -q install \"tensorflow==2.14.*\" onnx onnxruntime onnxsim coremltools --upgrade\n",
        "except Exception as e:\n",
        "    print(\"Falling back to tensorflow-cpu...\")\n",
        "    !pip -q install \"tensorflow-cpu==2.14.*\" onnx onnxruntime onnxsim coremltools --upgrade"
      ],
      "metadata": {
        "id": "zpfbf8OR0bTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "try:\n",
        "    CLASSES\n",
        "except NameError:\n",
        "    CLASSES = ['Car','Pedestrian','Cyclist']  # fallback\n",
        "labels_txt = Path(\"labels.txt\")\n",
        "labels_txt.write_text(\"\\n\".join(CLASSES))\n",
        "print(\"labels.txt written with\", len(CLASSES), \"classes.\")\n"
      ],
      "metadata": {
        "id": "tB6mdXOR0bd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Free as much memory as possible before heavy exports\n",
        "import gc, torch\n",
        "try:\n",
        "    del model\n",
        "except:\n",
        "    pass\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "6IgGYrkq9BSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "EXPORTS_DIR = Path(\"exports\"); EXPORTS_DIR.mkdir(exist_ok=True)\n",
        "exp_model = YOLO(str(BEST_PT))\n",
        "\n",
        "# ONNX\n",
        "onnx_path = exp_model.export(format=\"onnx\", opset=12, dynamic=True)\n",
        "shutil.copy2(onnx_path, EXPORTS_DIR / Path(onnx_path).name)\n",
        "\n",
        "# TFLite FP32\n",
        "tfl_fp32 = exp_model.export(format=\"tflite\")\n",
        "shutil.copy2(tfl_fp32, EXPORTS_DIR / Path(tfl_fp32).name)\n",
        "\n",
        "# TFLite FP16 (often best for Flutter + NNAPI/GPU)\n",
        "tfl_fp16 = exp_model.export(format=\"tflite\", half=True)\n",
        "shutil.copy2(tfl_fp16, EXPORTS_DIR / Path(tfl_fp16).name)\n",
        "\n",
        "# SavedModel (for custom INT8 conversion)\n",
        "saved_dir = exp_model.export(format=\"saved_model\")\n",
        "dst_saved = EXPORTS_DIR / \"saved_model\"\n",
        "if dst_saved.exists(): shutil.rmtree(dst_saved)\n",
        "shutil.copytree(saved_dir, dst_saved)\n",
        "\n",
        "# TorchScript (optional)\n",
        "ts_path = exp_model.export(format=\"torchscript\")\n",
        "shutil.copy2(ts_path, EXPORTS_DIR / Path(ts_path).name)\n",
        "\n",
        "# NCNN (optional)\n",
        "ncnn_dir = exp_model.export(format=\"ncnn\")\n",
        "dst_ncnn = EXPORTS_DIR / \"ncnn\"\n",
        "if dst_ncnn.exists(): shutil.rmtree(dst_ncnn)\n",
        "shutil.copytree(ncnn_dir, dst_ncnn)\n",
        "\n",
        "# CoreML (optional, for iOS later)\n",
        "try:\n",
        "    mlmodel_path = exp_model.export(format=\"coreml\")\n",
        "    shutil.copy2(mlmodel_path, EXPORTS_DIR / Path(mlmodel_path).name)\n",
        "except Exception as e:\n",
        "    print(\"CoreML export skipped:\", e)\n",
        "\n",
        "# Keep best.pt + labels.txt\n",
        "shutil.copy2(BEST_PT, EXPORTS_DIR / \"best.pt\")\n",
        "shutil.copy2(labels_txt, EXPORTS_DIR / labels_txt.name)\n",
        "\n",
        "print(\" Exported to:\", EXPORTS_DIR.resolve())\n"
      ],
      "metadata": {
        "id": "RV1PnxMq0bjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, random, cv2, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "assert (Path(\"exports\") / \"saved_model\").exists(), \"Missing exports/saved_model for INT8 conversion.\"\n",
        "dst_saved = Path(\"exports\") / \"saved_model\"\n",
        "\n",
        "cand_dirs = [\n",
        "    Path(\"./kitti_phase1/kitti_yolo/images/train\"),\n",
        "    Path(\"./kitti_phase1/kitti_yolo/images/val\"),\n",
        "    Path(\"/kaggle/input/kitti-dataset/data_object_image_2/training/image_2\")\n",
        "]\n",
        "img_pool = []\n",
        "for d in cand_dirs:\n",
        "    if d.exists():\n",
        "        img_pool += list(d.glob(\"*.png\"))\n",
        "img_pool = sorted(set(img_pool))\n",
        "assert img_pool, \"No images available for INT8 representative dataset.\"\n",
        "sample = random.sample(img_pool, min(100, len(img_pool)))  # was 150\n",
        "\n",
        "def rep_ds(imgsz=640):\n",
        "    for p in sample:\n",
        "        im = cv2.imread(str(p))\n",
        "        if im is None:\n",
        "            continue\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "        im = cv2.resize(im, (imgsz, imgsz)).astype(np.float32) / 255.0\n",
        "        yield [np.expand_dims(im, 0)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(dst_saved))\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = lambda: rep_ds()\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# converter.inference_input_type = tf.uint8\n",
        "# converter.inference_output_type = tf.uint8\n",
        "\n",
        "tfl_int8 = converter.convert()\n",
        "int8_path = Path(\"exports/best_int8.tflite\")\n",
        "int8_path.write_bytes(tfl_int8)\n",
        "print(\"INT8 saved:\", int8_path, \"size(MB)=\", round(int8_path.stat().st_size/1e6,2))"
      ],
      "metadata": {
        "id": "ICV5QkBS0bor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, hashlib, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "def sha256(p: Path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(1<<20), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "artifacts = []\n",
        "for p in Path(\"exports\").rglob(\"*\"):\n",
        "    if p.is_file():\n",
        "        artifacts.append({\"path\": str(p.relative_to(\"exports\")),\n",
        "                          \"bytes\": p.stat().st_size,\n",
        "                          \"sha256\": sha256(p)})\n",
        "\n",
        "Path(\"exports_manifest.json\").write_text(json.dumps({\n",
        "    \"best_pt\": str(BEST_PT),\n",
        "    \"classes\": CLASSES,\n",
        "    \"artifacts\": artifacts\n",
        "}, indent=2))\n",
        "\n",
        "with zipfile.ZipFile(\"all_model_exports.zip\",\"w\",compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for a in artifacts:\n",
        "        z.write(Path(\"exports\")/a[\"path\"], arcname=Path(\"exports\")/a[\"path\"])\n",
        "    z.write(\"exports_manifest.json\")\n",
        "\n",
        "print(\"all_model_exports.zip ready.\")\n"
      ],
      "metadata": {
        "id": "xBQJrVWG0buM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
